{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-19T09:44:41.853625Z","iopub.execute_input":"2023-08-19T09:44:41.854123Z","iopub.status.idle":"2023-08-19T09:44:41.864922Z","shell.execute_reply.started":"2023-08-19T09:44:41.854084Z","shell.execute_reply":"2023-08-19T09:44:41.863766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import FunctionTransformer,LabelEncoder\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:45:13.769767Z","iopub.execute_input":"2023-08-19T09:45:13.770144Z","iopub.status.idle":"2023-08-19T09:45:13.777195Z","shell.execute_reply.started":"2023-08-19T09:45:13.770115Z","shell.execute_reply":"2023-08-19T09:45:13.775844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/spam-mails-dataset/spam_ham_dataset.csv\",index_col = 0)\ndf.drop('label_num' , axis = 1 ,inplace = True)\n# df.columns = ['text' , 'target']\nlabel_encoder = LabelEncoder()\ndf['target']= label_encoder.fit_transform(df['label'])\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:45:14.797768Z","iopub.execute_input":"2023-08-19T09:45:14.798149Z","iopub.status.idle":"2023-08-19T09:45:14.890383Z","shell.execute_reply.started":"2023-08-19T09:45:14.798110Z","shell.execute_reply":"2023-08-19T09:45:14.889367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef text_transform(desc):\n    text = desc.lower()\n    text = nltk.word_tokenize(text)\n    words = [word for word in text if word.isalnum()]\n    words = [word for word in words if word not in stopwords.words('english')]\n\n    # Apply stemming using PorterStemmer\n    stemmer = PorterStemmer()\n    stemmed_words = [stemmer.stem(word) for word in words]\n\n    return \" \".join(stemmed_words)\n\ndef data_preprocessing(df):\n    df[\"transformed_text\"] = df['text'].apply(text_transform)\n    return df[\"transformed_text\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:45:19.629812Z","iopub.execute_input":"2023-08-19T09:45:19.630214Z","iopub.status.idle":"2023-08-19T09:45:19.638419Z","shell.execute_reply.started":"2023-08-19T09:45:19.630183Z","shell.execute_reply":"2023-08-19T09:45:19.637194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(['target' , 'label'] ,axis = 1).copy()\ny = df['target'].values\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=2)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:45:20.821467Z","iopub.execute_input":"2023-08-19T09:45:20.821882Z","iopub.status.idle":"2023-08-19T09:45:20.837772Z","shell.execute_reply.started":"2023-08-19T09:45:20.821849Z","shell.execute_reply":"2023-08-19T09:45:20.836340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:45:23.124715Z","iopub.execute_input":"2023-08-19T09:45:23.125105Z","iopub.status.idle":"2023-08-19T09:45:23.135472Z","shell.execute_reply.started":"2023-08-19T09:45:23.125076Z","shell.execute_reply":"2023-08-19T09:45:23.134579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a pipeline\npipeline = Pipeline([\n    ('data_preprocessing', FunctionTransformer(func=data_preprocessing, validate=False)),\n    ('vectorization', TfidfVectorizer(max_features=3000)),\n    ('SVC', SVC(kernel='sigmoid', gamma=1.0))\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:45:28.836912Z","iopub.execute_input":"2023-08-19T09:45:28.837370Z","iopub.status.idle":"2023-08-19T09:45:28.843773Z","shell.execute_reply.started":"2023-08-19T09:45:28.837336Z","shell.execute_reply":"2023-08-19T09:45:28.842545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the pipeline\npipeline.fit(X_train, y_train)\n\n# Make predictions\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:45:29.908124Z","iopub.execute_input":"2023-08-19T09:45:29.909350Z","iopub.status.idle":"2023-08-19T09:48:10.789105Z","shell.execute_reply.started":"2023-08-19T09:45:29.909311Z","shell.execute_reply":"2023-08-19T09:48:10.787900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('trained_pipeline.pkl', 'wb') as file:\n    pickle.dump(pipeline, file)\n\nprint(\"Trained pipeline saved to 'trained_pipeline.pkl'\")","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:48:44.109212Z","iopub.execute_input":"2023-08-19T09:48:44.109612Z","iopub.status.idle":"2023-08-19T09:48:44.144611Z","shell.execute_reply.started":"2023-08-19T09:48:44.109581Z","shell.execute_reply":"2023-08-19T09:48:44.143722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-08-19T09:49:33.490426Z","iopub.execute_input":"2023-08-19T09:49:33.490837Z","iopub.status.idle":"2023-08-19T09:49:33.499084Z","shell.execute_reply.started":"2023-08-19T09:49:33.490806Z","shell.execute_reply":"2023-08-19T09:49:33.497816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.DataFrame(data = [X_test['text'].iloc[0]] , columns = ['text'])\ntest_data","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:00:33.803305Z","iopub.execute_input":"2023-08-19T10:00:33.803733Z","iopub.status.idle":"2023-08-19T10:00:33.813459Z","shell.execute_reply.started":"2023-08-19T10:00:33.803698Z","shell.execute_reply":"2023-08-19T10:00:33.812703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:00:34.320363Z","iopub.execute_input":"2023-08-19T10:00:34.321705Z","iopub.status.idle":"2023-08-19T10:00:34.373365Z","shell.execute_reply.started":"2023-08-19T10:00:34.321661Z","shell.execute_reply":"2023-08-19T10:00:34.371990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}